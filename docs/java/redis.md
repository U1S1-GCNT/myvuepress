# Redis与Mysql一致性问题处理

#### 1、想要提高应用的性能，可以引入「缓存」来解决

> 随着业务量的增长，你的项目请求量越来越大，这时如果每次都从数据库中读数据，那肯定会有性能问题。这个阶段通常的做法是，引入「缓存」来提高读性能
>
> 引入缓存之后，你就会面临一个问题：之前数据只存在数据库中，现在要放到缓存中读取，具体要怎么存呢？
>
> 最简单直接的方案是「全量数据刷到缓存中」：
>
> - 数据库的数据，全量刷入缓存（不设置失效时间）
> - 写请求只更新数据库，不更新缓存
> - 启动一个定时任务，定时把数据库的数据，更新到缓存中
>
> ![](img/v2-abe00a421581a137ba64c80d5233b1aa_720w.jpg)
>
> 缺点也很明显，有 2 个问题：
>
> 1. 缓存利用率低：不经常访问的数据，还一直留在缓存中
> 2. 数据不一致：因为是「定时」刷新缓存，缓存和数据库存在不一致（取决于定时任务的执行频率）
>
> 所以，这种方案一般更适合业务「体量小」，且对数据一致性要求不高的业务场景。

#### 2、引入缓存后，需要考虑缓存和数据库一致性问题，可选的方案有：「更新数据库 + 更新缓存」、「更新数据库 + 删除缓存」



#### 3、更新数据库 + 更新缓存方案，在「并发」场景下无法保证缓存和数据一致性，且存在「缓存资源浪费」和「机器性能浪费」的情况发生



#### 4、在更新数据库 + 删除缓存的方案中，「先删除缓存，再更新数据库」在「并发」场景下依旧有数据不一致问题，解决方案是「延迟双删」，但这个延迟时间很难评估，所以推荐用「先更新数据库，再删除缓存」的方案



#### 5、在「先更新数据库，再删除缓存」方案下，为了保证两步都成功执行，需配合「消息队列」或「订阅变更日志」的方案来做，本质是通过「重试」的方式保证数据一致性

> 引入消息队列来解决这个问题，是比较合适的
>
> ![](img/v2-e45f274824556f439248e617c3b7784a_720w.jpg)
>
> 订阅变更日志，目前也有了比较成熟的开源中间件，例如阿里的 canal，使用这种方案的优点在于：
>
> - 无需考虑写消息队列失败情况：只要写 MySQL 成功，Binlog 肯定会有
> - 自动投递到下游队列：canal 自动把数据库变更日志「投递」给下游的消息队列
>
> 当然，与此同时，我们需要投入精力去维护 canal 的高可用和稳定性。

至此，我们可以得出结论，想要保证数据库和缓存一致性，推荐采用「先更新数据库，再删除缓存」方案，并配合「消息队列」或「订阅变更日志」的方式来做。



#### 6、在「先更新数据库，再删除缓存」方案下，「读写分离 + 主从库延迟」也会导致缓存和数据库不一致，缓解此问题的方案是「延迟双删」，凭借经验发送「延迟消息」到队列中，延迟删除缓存，同时也要控制主从库延迟，尽可能降低不一致发生的概率



## 可以做到强一致吗？

其实很难。

要想做到强一致，最常见的方案是 2PC、3PC、Paxos、Raft 这类一致性协议，但它们的性能往往比较差，而且这些方案也比较复杂，还要考虑各种容错问题。

相反，这时我们换个角度思考一下，我们引入缓存的目的是什么？

没错，性能。

一旦我们决定使用缓存，那必然要面临一致性问题。性能和一致性就像天平的两端，无法做到都满足要求。

而且，就拿我们前面讲到的方案来说，当操作数据库和缓存完成之前，只要有其它请求可以进来，都有可能查到「中间状态」的数据。

所以如果非要追求强一致，那必须要求所有更新操作完成之前期间，不能有「任何请求」进来。

虽然我们可以通过加「分布锁」的方式来实现，但我们要付出的代价，很可能会超过引入缓存带来的性能提升。

所以，既然决定使用缓存，就必须容忍「一致性」问题，我们只能尽可能地去降低问题出现的概率。

同时我们也要知道，缓存都是有「失效时间」的，就算在这期间存在短期不一致，我们依旧有失效时间来兜底，这样也能达到最终一致。